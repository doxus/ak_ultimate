% !TeX spellcheck = pl_PL

\newpage
\part{Pytania otwarte}
	\section{2010, Termin I (odpowiedzi z forum)}
		\begin{enumerate}
			\item \textbf{Które cechy architektury CISC zostały zmienione i w jaki sposób w architekturze RISC?}
			\begin{itemize}
				\item RISC:
				\begin{itemize}
					\item niezbyt duża lista rozkazów, rozkazu wykonywane w zasadzie w 1 cyklu (zmiana)
					\item  niewielka liczba trybów adresowania (zmiana)
					\item stała długość i prosty format rozkazu (chyba też zmiana)
					\item model obliczeń rejestr-rejestr, wszystkie argumenty są w rejestrach (zmiana) 
					\item dostęp do pamięci jedynie dzięki rozkazom STORE i LOAD
					\item duża ilość rejestrów uniwersalnych (chyba też zmiana)
					\item jednostka sterująca zbudowana jako układ
					\item intensywne wykorzystanie potokowości
					\item stosowanie kompilatorów o dużych możliwościach optymalizacyjnych
				\end{itemize}
				\item Cechy:
				\begin{itemize}
					\item duża liczba rozkazów
					\item duża liczba trybów adresacji (5 – 20, Vax $ \rightarrow $ 20 )
					\item model obliczeń pamięć – pamięć
					\item komplikowana struktura sprzętu, przy małym wykorzystaniu rozkazów złożonych
					\item duży rozrzut cech rozkazów w zakresie: złożoności, długości, czasu wykonania
				\end{itemize}
			\end{itemize}
			\label{itm:risc}
			
			\item \textbf{Wymień najważniejsze cechy architektury procesorów superskalarnych.}
			\label{itm:superskalar}
			\begin{itemize}
				\item Kilka potokowych jednostek operacyjnych
				\item Wykonywanie kilku rozkazów w 1 takcie
				\item Honieczność pobrania z PaO kilku rozkazów jednym takcie
			\end{itemize}
			
			
			\item \textbf{Wyjaśnij na czym polega problem zależności między danymi przy potokowej realizacji rozkazów. Podaj przykłady rozwiązania tego problemu w jednopotokowych procesorach RISC.}
			\begin{itemize}
				\item $ I1: R3 \leftarrow R3 op R5 $\\
					$ I2: R4 \leftarrow R3 + 1 $\\
					$ I3: R3 \leftarrow R5 + 1 $\\
					$ I4: R7 \leftarrow R3\:op\:R4 $
				\item 
				\begin{itemize}
					\item prawdziwa zależność danych (RAW) - rozkaz I2 musi czekać na wykonanie rozkazu I1, podobnie I4 musi czekać na I3
					\item zależność wyjściowa (WAW) - gdyby rozkazy I1 oraz I3 były realizowane równolegle (np. w różnych jednostkach funkcjonalnych), to wykonanie I3 musi się zakończyć po I1.
					\item antyzależność (WAR) - w przypadku równoległej realizacji rozkazów I2 oraz I3 (lub zmiany kolejności tych rozkazów), wykonanie rozkazu I3 nie może być zakończone, dopóki nie nastąpi pobranie argumentu (odczyt) w rozkazie I2.
				\end{itemize}
				\newpage
				\item Rozwiązania:
				\begin{itemize}
					\item NOP
					\item Proces przemianowania rejestrów (może to pomóc; nie jestem pewien)
					\item Wstrzymanie napełniania potoku
					\item Optymalizacja kodu na poziomie kompilacji / linkowania (odpowiedzialność zrzucona na kompilator)
				\end{itemize}
			\end{itemize}
			\label{itm:potok}
			\item \textbf{Omów budowę systemów o niejednorodnym dostępie do pamięci (ccNUMA)}\\
			Komputery w architekturze NUMA należą do systemów MIMD o niejednolitym dostępie do pamięci. Bierze to się stąd, iż każdy procesor ma własną pamięć; jednak do tej pamięci ma również dostęp każdy inny procesor, ztą tylko różnicą, że czas dostępu do takiej pamięci jest dużo większy niż czas dostępu do pamięci, którą dany procesor posiada. Zaliczenie procesora z pamięcią i jednostką zarządzającą pamięcią nazywa się węzłem. Zadaniem takiej jednostki zarządzającej pamięcią jest odpowiednie kierowanie adresów i danych w zależności o którą pamięć nam chodzi (lokalną dla danego procesora czy też znajdującą się przy innym procesorze). We współczesnych rozwiązaniach praktycznych duży nacisk kładzie się na zgodność (spójność) pamięci podręcznej (są to systemy typu CC-NUMA)\\
			MIMD typu C.C.-NUMA  (ze spójnością pamięci podręcznej).
			
			\item \textbf{Wymień i krótko scharakteryzuj rozwiązania konstrukcyjne serwerów używanych do budowy klastrów.}
			\begin{itemize}
				\item Serwery wolnostojące
				\item Serwery stelażowe
				\begin{itemize}
					\item Zalety:
					\begin{itemize}
						\item możliwość instalowania obok siebie serwerów różnych dostawców
					\end{itemize}
					\item Wady:
					\begin{itemize}
						\item kable zasilające
						\item kable sieciowe
						\item chłodzenie
					\end{itemize}
				\end{itemize}
				\item Serwery kasetowy
				\begin{itemize}
					\item Zalety:
					\begin{itemize}
						\item jedna obudowa typu blade
						\item wspólne zasilanie i chłodzenie - jeden kabel zasilający
						\item prostsze okablowanie sieciowe 
						\item proste zarządzanie
						\item mniejsze wymiary i duża gęstość upakowania
					\end{itemize}
					\item Wady:
					\begin{itemize}
						\item możliwość instalowania tylko identycznych serwerów
					\end{itemize}
				\end{itemize}
			\end{itemize}
		\end{enumerate}
	
	\newpage
	\section{2013, Termin I (odpowiedzi z forum)}
		\begin{enumerate}	
			\item \textbf{Wymień cechy architektury superskalarnej.}\\
			Patrz: \ref{itm:superskalar}
			\item \textbf{Uszereguj systemy wieloprocesorowe i klastry rosnąco wg skalowalności.}\\
			Według mnie chociaż nie jestem tego pewien to systemy wieloprocesorowe trzeba by uszeregować tak:
			\begin{itemize}
				\item komputery macierzowe (jeżeli traktować elementy przetwarzające jako osobne jednostki) - ciężko zwiększać elementy przetwarzające lub układy macierzowe jako peryferia komputera
				\item UMA - ciężkie do rozbudowy ze względu na pojedynczą magistralę lub przełącznicę
				\item NUMA - średnie w rozbudowie
				\item MPP - łatwe w rozbudowie; wystarczy dokładać procesory i zadbać o przepływ danych (wymiana komunikatów)
				\item Klastry - wydajnościowe i niezawodnościowe; pracujące na wspólnych dyskach; każdy z nich ma osobny, niezależnie utrzymywany system operacyjny
			\end{itemize}
			\item \textbf{Scharakteryzuj ogólnie systemy typu klaster.}
			\begin{itemize}
				\item Sieci łączące – standardy: Gigabit Ethernet, Infiniband
				\item Komunikacja między węzłami (procesami) – przesył komunikatów
				\item Bardzo wysoka skalowalność
				\item Cele budowy: wysoka wydajność lub/i wysoka niezawodność
				\item Korzystny wskaźnik: cena/wydajność
				\item Według mnie jeszcze oprogramowanie, które umożliwi prawidłową pracę tych wszystkich komputerów
			\end{itemize}
			\item \textbf{Wyjaśnij, na czym polega problem zależności między danymi przy potokowej realizacji rozkazów. Podaj przykłady rozwiązania tego problemu w jednopotokowych procesorach RISC i w procesorach superskalarnych.}\\
			Patrz: \ref{itm:potok}
			
			\item \textbf{Co jest celem sprzętowego sterowania współbieżną realizacją wielu wątków w jednym rdzeniu? Jakie są metody i jakie warunki sprzętowej realizacji wielowątkowości?}\\
			Celem współbieżnej realizacji dwóch (lub więcej) wątków w jednym procesorze (rdzeniu) jest 
			minimalizacja strat cykli powstałych w trakcie realizacji pojedynczego wątku w wyniku:
			\begin{itemize}
				\item chybionych odwołań do pamięci podręcznej, 
				\item błędów w przewidywaniu rozgałęzień, 
				\item zależności między argumentami kolejnych rozkazów.
			\end{itemize}
			Warunki sprzętowej realizacji wielowątkowości:
			\begin{itemize}
				\item powielenie zestawów rejestrów uniwersalnych (lub powielenie tabel mapowania rejestrów)
				\item powielenie liczników rozkazów
				\item powielenie układów dostępu do pamięci podręcznej (tabel stron)
				\item powielenie sterowników przerwań 
			\end{itemize}
		\end{enumerate}
		
	\section{2014, termin I, NSI}
		\begin{enumerate}
			\item \textbf{Scharakteryzuj ogólnie procesory o architekturze superskalarnej}
			\begin{itemize}
				\item Procesor superskalarny posiada potoki, które umożliwiają wykonywanie większej niż 1 liczby rozkazów w 1 takcie.
				\item Potrafi załadować kilka rozkazów z pamięci operacyjnej w jednym takcie procesora.
				\item Z tych powodów wynika hazard sterowania oraz hazard danych.
				\item Hazard sterowania wynika z potokowości i polega na możliwości błędnego przewidywania rozgałęzień i warunków. Eliminuje się go stosują układy przewidywania rozgałęzień (sprzętowo) lub przez programistę metodą skoków opóźnionych (programowo).
				\item Hazard danych również wynika z potokowości procesora, polega na przetwarzania danych w taki sposób, że równoległe wykonywania operacji, może skutkować błędnym wykonaniem programu. Można wyróżnić 3 rodzaje zależności:
				\begin{itemize}
					\item Prawdziwa zależność danych (\emph{RAW - Read After Write}) - próba odczytania zmiennej która jest jednocześnie zapisywana. Można rozwiązać przez szynę zwrotną (wyprzedzające pobieranie argumentu) lub metodę przemianowania rejestrów.
					\item Zależność wyjściowa (\emph{WAW - Write After Write}) - próba zapisania zmiennej która jest jednocześnie zapisywana. Ten rodzaj zależności musi być wykrywany sprzętowo.
					\item Antyzależność (\emph{WAR - Write After Read}) - próba zapisania zmiennej która jest jednocześnie odczytywana. Można rozwiązać przez wstrzymanie napełniania potoku na 1 takt lub metodę przemianowania rejestrów.
				\end{itemize}
			\end{itemize}
			\item \textbf{Wyjaśnij na czym polega różnica w wykonaniu rozkazów wektorowych w komputerach wektorowych i macierzowych}
			\begin{itemize}
				\item W komputerach wektorowych czas wykonania rozkazu wektorowego jest wprost proporcjonalny do długości wektora. Z kolei w komputerach macierzowych, jeśli ten posiada wystarczającą liczbę jednostek (co najmniej długość wektora x długość wektora), czas ten jest stały.
			\end{itemize}
			\item \textbf{Scharakteryzuj ogólnie systemy typu klaster}
			\begin{itemize}
				\item Pamięć systemów klaster jest rozproszona fizycznie i logicznie.
				\item Węzłem klastra może być albo komputer osobisty (PC), albo system SMP jako serwer.
				\item Każdy węzeł klastra musi posiadać osobny system operacyjny.
				\item Klaster może być węzłem systemu MPP.
				\item Za komunikację odpowiada przesył komunikatów.
				\item Węzły są połączone za pomocą sieci specjalizowane SAN lub zwykłej sieci LAN.
				\item Klastry charakteryzują się wysoką niezawodnością i wydajnością za rozsądną cenę.
				\item Bardzo wysoka skalowalność.
			\end{itemize}
			\item \textbf{Wyjaśnij na czym polega problem zależności między danymi przy potokowej realizacji rozkazów. Podaj przykłady rozwiązania tego problemu w procesorach RISC.}
			\begin{itemize}
				\item przy potokowej realizacji rozkazów występuje hazard danych, czyli zależności między danymi. Można wyróżnić ich 3 rodzaje:
				\begin{itemize}
					\item Prawdziwa zależność danych (\emph{RAW - Read After Write}) - próba odczytania zmiennej która jest jednocześnie zapisywana. Można rozwiązać przez szynę zwrotną (wyprzedzające pobieranie argumentu) lub metodę przemianowania rejestrów.
					\item Zależność wyjściowa (\emph{WAW - Write After Write}) - próba zapisania zmiennej która jest jednocześnie zapisywana. Ten rodzaj zależności musi być wykrywany sprzętowo.
					\item Antyzależność (\emph{WAR - Write After Read}) - próba zapisania zmiennej która jest jednocześnie odczytywana. Można rozwiązać przez wstrzymanie napełniania potoku na 1 takt lub metodę przemianowania rejestrów.
				\end{itemize}
			\end{itemize}
			\item \textbf{Omów organizację pamięci podręcznych (PaP) oraz metody sprowadzania danych z pamięci operacyjnej do PaP? Dlaczego stosuje się pamięci podręczne.}
		\end{enumerate}
	\newpage
	\section{2015, Termin 0}
		\begin{enumerate}
			\item \textbf{Omów najważniejsze cechy architektury CUDA w szczególności model pamięci.}
			\begin{samepage}
				\begin{itemize}
					\item \emph{Cechy architektury}:
					\begin{itemize}
						\item CUDA to architektura wielordzeniowych procesorów graficznych, to uniwersalna architektura obliczeniowa wraz z równoległym modelem programistycznym, wspiera C i C++.
						\item Posiada uniwersalny procesor przetwarzający wierzchołki, piksele i geometrię oraz uniwersalne programy obliczeniowe.
						\item Posiada procesor wątków, który eliminuje "ręczne" zarządzanie rejestrami wektorowymi.
						\item Oparta jest o model SIMT (\emph{single-instruction multiple-thread}), gdzie wiele niezależnych wątków wykonuje równocześnie tę samą instrukcję.
						\item Model programistyczny dzieli kod na część wykonywaną przez procesor i część wykonywaną przez kartę graficzną.
					\end{itemize}
					\item \textbf{Wątki}:
					\begin{itemize}
						\item Każdy wątek niezależnie wykonują tę samą operację oraz ma swoją lokalną pamięć, dodatkowo wątki mają wspólną pamięć globalną i współdzieloną.
						\item Za komunikację między wątkami odpowiadają mechanizmy synchronizacji (\emph{barrier synchronization}).
						\item Wątki są automatycznie grupowane w bloki o geometrii 1, 2 lub 3-wymiarowej.
						\item Bloki grupowane są w siatkę (\emph{grid} - kratę) o geometrii 1, 2-wymiarowej.
						\item Bloki wątków tworzących siatkę muszą się wykonywać niezależnie.
					\end{itemize}
					\item \textbf{Model pamięci:}
					\begin{itemize}
						\item \textbf{Pamięć globalna} - duża, o czasie życia aplikacji, dostępna dla każdego wątku w dowolnym bloku, o długim czasie dostępu. W pamięci globalnej wyróżnia się:
						\begin{itemize}
							\item \textbf{Pamięć stałych} - mały fragment, który jest tylko do odczytu oraz jest \textit{cache}-owany, dzięki czemu dostęp do niego jest bardzo szybki. Czas życia oraz jej dostępność taka sama.
							\item \textbf{Pamięć lokalna} - wykorzystywana do przechowywania danych lokalnych wątku, które nie mieszczą się w rejestrach
							\item \textbf{Pamięć tekstur} - posiada specyficzne metody adresowania i \textit{cache}-owanie dla zastosowań graficznych
						\end{itemize}
						\item \textbf{Pamięć współdzielona} - niewielka, o czasie życia bloku, dostępna dla każdego wątku w bloku dla którego jest dedykowana, o bardzo krótkim czasie dostępu.
						\item \textbf{Rejestry}	- niewielka, bardzo szybka, o czasie życia wątku. Tylko jeden wątek może w danym momencie korzystać z danego rejestru.
					\end{itemize}
				\end{itemize}
			\end{samepage}
			\item \textbf{Omów budowę systemów o niejednorodnym dostępie do pamięci (NUMA).}
			\begin{samepage}
			\begin{itemize}
				\item Systemy NUMA zbudowane są z wielu procesorów, gdzie każdy procesor posiada własną, bardzo szybką pamięć lokalną.
				\item Dodatkowo procesory posiadają wspólną, ogromną pamięć wspólną.
				\item Dostęp do nielokalnej pamięci jest znacznie wolniejszy niż do lokalnej (ok. 10 razy).
				\item W celu zapewnienia spójności między pamięciami podręcznymi stosowane są węzły i katalogi, i tylko katalogi, które są znacznie lepsze od protokołu MESI.
				\item Można wyróżnić podkategorie systemów: NC-NUMA (non-cached) i CC-NUMA (cache coherent)
				\item Systemy te posiadają średniej jakości skalowalność
				\item Pamięć podręczna jest fizycznie rozproszona, ale logicznie wspólna.
				\item Dostęp do pamięci nielokalnej odbywa się z użyciem katalogów oraz odczytywanie całych linii pamięci podręcznej.
				\item Architektura NUMA jest bardzo efektywna dla aplikacji, które częściej odczytują z nielokalnej pamięci i nieefektywna dla aplikacji, które części zapisują do niej.\\
				Przy zapisie trzeba zaktualizować stan tej linii we wszystkich węzłach, które je pobrały do siebie.
			\end{itemize}
			\end{samepage}
			\item \textbf{Porównaj realizację rozkazów wektorowych w komputerach wektorowych i macierzowych.}
			\begin{samepage}
			\ref{ss:wektor}
			\begin{itemize}
				\item \textbf{W komputerze wektorowym}:
				\begin{itemize}
					\item Szybkość realizacji rozkazów jest liniowo proporcjonalna do długości wektora.
					\item Moc obliczeniowa rośnie logarytmicznie (nieliniowo) wraz ze zwiększeniem długości wektora.
					\item Przyspieszenie (stosunek czasu wykonywania na komputerze szeregowym do czasu na wektorowym) jest w idealnym przypadku równa długości wektora.
					\item Efektywność wykonywania rozkazów dąży do pewnej stałej wartości, która jest efektywnością idealną.
				\end{itemize}
				\item \textbf{Z kolei w komputerze macierzowym}:
				\begin{itemize}
					\item Rozkaz wektorowy może być wykonywany w jednym kroku (jeśli jest wystarczająca liczba jednostek przetwarzających), czyli w stałym czasie.
					\item Dzieje się tak dzięki sieci elementów przetwarzających.
				\end{itemize}
			\end{itemize}
			\end{samepage}
			\item \textbf{Wymień różnice między systemami SMP a MPP.}
			\begin{samepage}
			\begin{itemize}
				\item SMP posiada pamięć logicznie wspólną, ale może ona być fizycznie jednorodna (UMA) lub rozproszona (NUMA). Z kolei MPP posiada pamięć fizycznie i logicznie rozproszoną.
				\item MMP jest znacznie bardziej skalowalne niż SMP (UMA - słabo, NUMA - średnio).
				\item W SMP wymagany jest mechanizm do zachowania spójności pamięci podręcznych procesorów - może to być protokół MESI (UMA) lub katalogi (UMA i NUMA).
				\item W MPP do kontroli wystarcza przesył komunikatów. Jest on realizowany programowo (MPP I generacji) lub sprzętowo przez routery (MPP II generacji).
				\item W SMP istnieje jedna wspólna pamięć, z kolei w MPP każdy węzeł ma swoją pamięć lokalną plus opcjonalnie wspólną.
				\item W MPP jest wolniejsza komunikacji między węzłami sieci - potrzebna jest wymiana większej liczby informacji.
				\item SMP węzłem jest zwykły procesor, w MPP jest to procesor lub system wieloprocesorowy (właśnie SMP).
			\end{itemize}
			\end{samepage}
			
			\item \textbf{Omów rozwiązania stosowane w klastrach o wysokiej niezawodności.}
			\begin{samepage}
			\begin{itemize}
				\item Redundancja węzłów (mocy obliczeniowej) - większa moc obliczeniowa, więcej mocy w zapasie, różne tryby pracy klastrów (aktywny-pasywny, pasywny-pasywny, mieszane)
				\item Dostęp do wspólnych zasobów (pamięci zewnętrznych) - więcej pamięci, współdzielona lub nie ("współdziel wszystko", "nie współdziel nic").
				\item \textit{Mirroring} dysków - zabezpieczenie przed utratą danych, zapis na dwóch dyskach jednocześnie tych samych danych
				\item Mechanizmy kontrolujące funkcjonowanie węzłów - efektywniejsza praca całości jako jednego systemu
				\item Redundancja sieci łączących (dla 3 rodzajów sieci) - przypadku błędu sieci klaster nie przestaje działać, tylko inna sieć przejmuje kontrolę
				\item Redundancja zasilania - wincyj mocy i prundu
				\item Mechanizmy kontrolujące funkcjonowanie węzłów - "Heartbeat" oraz "Fail-over". Heartbeat to regularne wysyłanie sygnałów przez węzeł do sieci, które świadczą o poprawnej pracy. Jeżeli "bicie serca" zostanie przerwane / zakłócone, do akcji wkracza Fail-over - obsługa awarii. Ten przełącza system, który uległ awarii na system rezerwowy. Poprzez Fail-back określa się powrót do stanu sprzed awarii.
			\end{itemize}
			\end{samepage}
		\end{enumerate}
